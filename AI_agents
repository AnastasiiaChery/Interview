
## Context Rotting

Context rotting (або context drift) — це поступова втрата моделлю здатності дотримуватися початкових інструкцій під час довгих діалогів.

Причини:

* Attention dilution (увага розподіляється між великою кількістю токенів)
* Lost-in-the-middle effect
* Signal-to-noise degradation (логи та помилки перекривають архітектурний сигнал)

Як зменшити ефект:

* зберігати архітектуру у PLAN.md
* починати нову сесію після планування
* мінімізувати логи у контексті
* працювати короткими ітераціями

---

## Copilot CLI Tokenomics (2026)

Copilot CLI рахує **запити (requests)**, а не токени.

Формула вартості:
TotalCost = Σ(Requests × Multiplier) + ContextNoisePenalty

Приклад multipliers:

GPT-5 mini — 0x — lint, коментарі
Claude Haiku 4.5 — 0.33x — CRUD, тести
Claude Sonnet 4.5 — 1x — архітектура
Claude Opus 4.5 — 3x — критичні системи

---

## Agent Loop Trap

Один prompt може запускати кілька дій агента:

* планування
* створення файлу
* запуск тестів
* виправлення помилок

На «дорогих» моделях це швидко витрачає credits.

---

## Recommended Workflow

Planning:
Використовуйте Sonnet / Opus
Збережіть результат у PLAN.md

Implementation:
Використовуйте Haiku або GPT-5 mini

Tests & CRUD:
Використовуйте Haiku

Cleanup:
Використовуйте GPT-5 mini

---

## Ключовий принцип

Використовуйте:

* сильні моделі → для архітектури
* дешевші моделі → для реалізації
* нову сесію → після етапу планування

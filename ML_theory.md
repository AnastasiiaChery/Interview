# Лінійна регресія — конспект

## Що таке лінійна регресія
Лінійна регресія — це статистичний метод, який використовується для пошуку
лінійного зв’язку між змінними. У машинному навчанні вона описує залежність
між **ознаками (вхідними даними)** і **міткою (результатом)**.

Приклад: прогноз паливної економічності автомобіля (милі на галон)
на основі його ваги.

Загальна тенденція:
> чим більша вага автомобіля, тим менше миль на галон.

---

## Рівняння лінійної регресії
Модель записується як:

y' = b + wx

де:
- y' — прогнозоване значення (мітка)
- x — ознака
- w — вага (нахил прямої)
- b — зсув (перетин із віссю y)

Параметри **w** і **b** обчислюються під час навчання моделі.

---

## Приклад моделі
Для набору даних автомобілів:

y' = 30 − 3.6x

Прогноз:
якщо вага автомобіля = 4 (4000 фунтів), то

y' = 30 − 3.6 × 4 = 15.6

Отже, прогнозована паливна економічність:
**15.6 милі на галон**.

---

## Модель з кількома ознаками
Лінійна регресія може використовувати кілька ознак:

y' = b + w1x1 + w2x2 + ... + wn xn

Наприклад, для автомобіля:
- вага
- робочий об’єм двигуна
- прискорення
- кількість циліндрів
- кінські сили

Кожна ознака має власну вагу.

---

## Типові залежності
- Вага → негативна залежність із MPG
- Робочий об’єм → негативна залежність
- Кінські сили → негативна залежність
- Прискорення → позитивна залежність

---

## Висновок
Лінійна регресія — це проста й базова модель машинного навчання,
яка знаходить пряму, що найкраще описує залежність між даними,
і дозволяє робити прогнози.


# Лінійна регресія: втрати

## Що таке втрати
Втрати (loss) — це числова метрика, яка показує,
наскільки прогнози моделі відрізняються від фактичних значень.

Втрати = відстань між:
- прогнозованим значенням
- фактичним значенням

Мета навчання моделі — **мінімізувати втрати**.

---

## Відстань втрат
Втрати — це саме **відстань**, тому знак різниці не важливий.

Наприклад:
прогноз = 2, фактичне значення = 5  
відстань = 3

Щоб прибрати знак, використовують:
- модуль різниці
- квадрат різниці

---

## Основні типи втрат

### L1-втрати
Сума модулів різниці:


# Градієнтний спуск — конспект

## Що таке градієнтний спуск
Градієнтний спуск — це математичний метод оптимізації,
який **ітераційно знаходить ваги та зсув**, що **мінімізують втрати моделі**.

Модель починає навчання з випадкових значень параметрів,
а потім поступово їх покращує.

---

## Основні кроки алгоритму
1. Обчислити втрати для поточних ваг і зсуву.
2. Визначити напрямок зменшення втрат.
3. Оновити ваги й зсув невеликим кроком.
4. Повторювати процес до мінімізації втрат.

---

## Крива втрат (Loss curve)
Крива втрат показує:
- вісь X — ітерації
- вісь Y — втрати

Типова поведінка:
- на початку втрати швидко зменшуються
- далі зменшення сповільнюється
- після цього модель досягає **збіжності (convergence)**

Збіжність означає, що втрати майже не змінюються.

---

## Стан моделі під час навчання
- Початок — великі втрати, погані прогнози
- Середина — модель поступово покращується
- Кінець — модель найкраще відповідає даним

---

## Опукла функція втрат
Для лінійної регресії функція втрат є **опуклою**.

Це означає:
- існує один глобальний мінімум
- градієнтний спуск гарантовано рухається до нього

Поверхню втрат можна уявити як **чашу або пагорб, з якого котиться м’яч**.

---

## Мінімум втрат
Градієнтний спуск знаходить:
- оптимальну вагу
- оптимальний зсув

Наприклад:
w = −5.44
b = 35.94


Ці значення дають **найменші можливі втрати для набору даних**.

Важливо:
мінімальні втрати ≠ нульові втрати.

---

## Висновок
- Градієнтний спуск — основний алгоритм навчання лінійної регресії.
- Він ітераційно мінімізує функцію втрат.
- Збіжність означає досягнення мінімуму втрат.
- Завдяки опуклій функції втрат знаходиться глобальний мінімум.


# Гіперпараметри в машинному навчанні — конспект

## Параметри vs гіперпараметри
**Параметри** — це значення, які модель обчислює під час навчання:
- вага (w)
- зсув (b)

**Гіперпараметри** — це значення, які задає користувач і які
контролюють процес навчання.

Основні гіперпараметри:
- швидкість навчання (learning rate)
- розмір пакета (batch size)
- кількість епох (epochs)

---

## Швидкість навчання (Learning rate)
Швидкість навчання — це число, яке визначає,
**наскільки сильно змінюються параметри моделі на кожному кроці градієнтного спуску**.

Оновлення параметра:
зміна параметра = градієнт × швидкість навчання


### Вплив швидкості навчання
- **занадто мала** → навчання дуже повільне
- **занадто велика** → модель не збігається (втрати коливаються або зростають)
- **оптимальна** → швидка збіжність

Важливо:
> ідеальна швидкість навчання залежить від задачі.

---

## Розмір пакета (Batch size)
Розмір пакета — це **кількість прикладів, які модель обробляє
перед оновленням ваг і зсуву**.

### Типи градієнтного спуску

**Повний пакет (Batch gradient descent)**
- використовує весь набір даних
- стабільні оновлення
- повільний для великих даних

**Стохастичний градієнтний спуск (SGD)**
- розмір пакета = 1
- швидкі оновлення
- багато шуму в кривій втрат

**Мініпакетний SGD**
- пакет більше 1, але менший за весь набір
- баланс між швидкістю і стабільністю
- використовується найчастіше

---

## Епохи (Epochs)
**Епоха** — це один повний прохід моделі через весь навчальний набір.

Приклад:
- 1000 прикладів
- batch size = 100
- 1 епоха = 10 ітерацій

Навчання зазвичай триває **кілька епох**.

Що більше епох:
- модель може навчитися краще
- навчання триває довше

---

## Оновлення параметрів
Приклад:
- 1000 прикладів
- 20 епох

Повний пакет → 20 оновлень  
SGD → 20 000 оновлень  
Мініпакет (100) → 200 оновлень  

---

## Висновок
- Гіперпараметри контролюють процес навчання.
- Швидкість навчання визначає величину кроку оптимізації.
- Batch size визначає кількість прикладів за одну ітерацію.
- Epoch — це повний прохід по даних.
- Оптимальні значення гіперпараметрів зазвичай підбираються експериментально.


# Логістична регресія — обчислення ймовірності

## Що таке логістична регресія
Логістична регресія — це модель машинного навчання,
яка використовується для обчислення ймовірності події.

Результат моделі — число від 0 до 1.

Приклад:
0.932 → ймовірність спаму = 93.2%

Ймовірність можна:
- використовувати як є
- перетворювати на двійковий клас (0/1)

---

## Сигмоїдна функція
Щоб отримати значення від 0 до 1,
використовується сигмоїдна (логістична) функція:

σ(z) = 1 / (1 + e^(−z))

Властивості:
- S-подібна крива
- значення завжди між 0 і 1
- при z → +∞ → результат → 1
- при z → −∞ → результат → 0

---

## Лінійна частина моделі
Спочатку обчислюється лінійне значення:

z = b + wx

або для кількох ознак:

z = b + w1x1 + w2x2 + ... + wnxn

де:
- z — лінійний результат (логарифм шансів)
- b — зсув
- w — ваги
- x — ознаки

---

## Отримання ймовірності
Після цього застосовується сигмоїдна функція:

y' = σ(z)

y' — це ймовірність, яку прогнозує модель.

---

## Приклад
Лінійне рівняння:
z = 2x + 5

Приклад значень:
z = −10 → y' ≈ 0.00004
z = 0 → y' = 0.5
z = 5 → y' ≈ 0.993

Навіть якщо z дуже велике або мале,
результат сигмоїди завжди між 0 і 1.

---

## Висновок
- Логістична регресія використовується для задач класифікації.
- Модель спочатку обчислює лінійну комбінацію ознак.
- Сигмоїдна функція перетворює результат у ймовірність.
- Вихід моделі завжди в діапазоні (0, 1).


# Навчання логістичної регресії

Процес навчання моделі логістичної регресії подібний до навчання лінійної регресії,
але має дві ключові відмінності:

- використовується **логістична функція втрат**, а не квадратична
- **регуляризація є критично важливою**, щоб запобігти перенавчанню

---

## Логістична функція втрат

У лінійній регресії використовується **квадратична функція втрат (L2)**.
Вона добре працює для лінійних моделей із постійною швидкістю зміни виходу.

Наприклад:
```
y = 3x
```
Коли `x` збільшується на 1, `y` збільшується на 3.

У логістичній регресії зміна виходу **не є лінійною**, тому що
використовується **сигмоїдна функція (S-подібна крива)**.

Коли логарифм шансів `z` близький до 0,
невелика зміна `z` сильно впливає на результат.
Коли `z` дуже великий або дуже малий — зміни майже непомітні.

---

### Приклад значень сигмоїдної функції

| Вхідні дані | Вихід сигмоїди | Точність |
|-------------|---------------|---------|
| 5 | 0.993 | 3 |
| 6 | 0.997 | 3 |
| 7 | 0.999 | 3 |
| 8 | 0.9997 | 4 |
| 9 | 0.9999 | 4 |
| 10 | 0.99998 | 5 |

Якби використовувалася квадратична функція втрат,
потрібно було б зберігати більше точності,
коли значення наближаються до **0 або 1**.

---

## Логістична функція втрат (Binary Cross-Entropy)

Замість L2 використовується **логістична функція втрат**:

```
Loss = − ( y log(y') + (1 − y) log(1 − y') )
```

де:
- `D` — набір даних
- `y` — правильна мітка (0 або 1)
- `y'` — прогнозована ймовірність

Ця функція використовує **логарифм помилки**, а не відстань.

---

## Регуляризація в логістичній регресії

Регуляризація — це **штраф за складність моделі** під час навчання.

Вона дуже важлива для логістичної регресії,
тому що через асимптотичний характер сигмоїди
втрати можуть зменшуватися майже до нуля,
якщо модель має занадто багато параметрів.

Найпоширеніші підходи:

- **L2-регуляризація**
- **рання зупинка (early stopping)**

Рання зупинка — це припинення навчання,
коли значення функції втрат ще зменшується,
щоб уникнути перенавчання.

---

## Висновок
- Логістична регресія використовує іншу функцію втрат, ніж лінійна.
- Використовується **логістична (cross-entropy) функція втрат**.
- **Регуляризація є необхідною** для стабільного навчання.
- Найчастіше застосовують **L2-регуляризацію та early stopping**.


# Класифікація в логістичній регресії

З модуля **«Логістична регресія»** ви дізналися, як використовувати сигмоїдну функцію,
щоб перетворювати необроблені вихідні дані моделі на значення від 0 до 1,
а потім робити **ймовірнісні прогнози**.

Наприклад, модель може визначити, що електронний лист є спамом із
ймовірністю **75%**.

Але іноді потрібно отримати **не ймовірність, а конкретну категорію** —
наприклад, передбачити, чи є електронний лист:

* **Spam**
* **Not Spam**

---

## Що таке класифікація

**Класифікація** — це завдання прогнозування,
до якого з наперед визначених класів належить приклад.

У цьому модулі розглядається:

* як перетворити модель логістичної регресії, що прогнозує **ймовірність**,
  у модель **бінарної класифікації**
* як **вибирати поріг (threshold)** для прийняття рішення
* як **оцінювати якість класифікаційної моделі**

---

## Бінарна класифікація

У бінарній класифікації модель прогнозує **один із двох класів**.

Зазвичай це робиться через **поріг імовірності**:

```
якщо p ≥ 0.5 → клас 1
якщо p < 0.5 → клас 0
```

Наприклад:

```
p(spam) = 0.75 → Spam
p(spam) = 0.20 → Not Spam
```

---

## Оцінювання моделі класифікації

Для оцінювання класифікаційних моделей використовуються спеціальні метрики, наприклад:

* accuracy
* precision
* recall
* F1-score

Вони допомагають зрозуміти,
наскільки добре модель класифікує дані.



# Порогові значення і матриця плутанини

Припустимо, що модель логістичної регресії для виявлення спаму
прогнозує значення від **0 до 1**, які означають ймовірність того,
що лист є спамом.

Наприклад:
- 0.50 → 50% імовірність спаму
- 0.75 → 75% імовірність спаму
- 0.99 → 99% імовірність спаму

Але для практичного використання потрібно перетворити
ймовірність у **категорію**:
- spam
- not spam

---

## Поріг класифікації

Для цього використовується **порогове значення (threshold)**.

Правило класифікації:

```
якщо p ≥ threshold → позитивний клас (spam)
якщо p < threshold → негативний клас (not spam)
```

### Приклад
Прогнози моделі:
```
0.99
0.51
```

- threshold = 0.5 → обидва листи = spam
- threshold = 0.95 → spam лише 0.99

---

## Чому поріг 0.5 не завжди правильний

Поріг залежить від:
- **вартості помилки**
- **балансу класів**

Наприклад:
- якщо лише **0.01% листів — спам**, дані незбалансовані
- якщо **втрата важливого листа гірша**, ніж пропущений спам

У таких випадках поріг потрібно змінювати.

---

# Матриця плутанини (Confusion Matrix)

Матриця плутанини показує всі можливі результати класифікації.

| | Фактично позитивний | Фактично негативний |
|---|---|---|
| Прогнозовано позитивний | TP (істинно позитивний) | FP (хибнопозитивний) |
| Прогнозовано негативний | FN (хибнонегативний) | TN (істинно негативний) |

---

## Значення елементів

**TP (True Positive)**  
Спам правильно визначено як спам.

**FP (False Positive)**  
Не-спам помилково визначено як спам.

**FN (False Negative)**  
Спам помилково визначено як не-спам.

**TN (True Negative)**  
Не-спам правильно визначено.

---

## Суми

- TP + FP → всі **прогнозовані позитивні**
- FN + TN → всі **прогнозовані негативні**
- TP + FN → всі **фактичні позитивні**
- FP + TN → всі **фактичні негативні**

---

## Незбалансовані дані

Набір даних є **незбалансованим**, якщо
кількість позитивних і негативних прикладів сильно відрізняється.

Приклад:
- тисячі фотографій хмар
- рідкісний тип хмар з’являється лише кілька разів

---

## Вплив порогу

Різні пороги змінюють:
- TP
- FP
- FN
- TN

Зазвичай:
- більший поріг → менше FP, більше FN
- менший поріг → більше FP, менше FN

---

## Типи даних у прикладах

- **Розділені дані** — класи добре відокремлені
- **Нерозділені дані** — класи перекриваються
- **Незбалансовані дані** — позитивних прикладів мало


# Метрики класифікації: accuracy, recall, precision, FPR

Метрики оцінювання моделі класифікації обчислюються на основі
**матриці плутанини (TP, FP, TN, FN)**.

Вибір метрики залежить від:
- задачі
- вартості помилок
- балансу даних
- порогу класифікації

Усі метрики змінюються разом із порогом.

---

# Accuracy (точність класифікації)
Частка всіх правильних прогнозів.

Формула:
```
Accuracy = (TP + TN) / (TP + TN + FP + FN)
```

У прикладі зі спамом:
частка всіх листів, класифікованих правильно.

### Коли використовувати
- збалансовані дані
- загальна оцінка моделі

### Проблема
Для незбалансованих даних може бути оманливою.

Наприклад:
- 1% спаму
- модель завжди каже "not spam"
- accuracy = 99% (але модель марна)

---

# Recall (повнота, True Positive Rate)
Частка позитивних прикладів, які модель знайшла.

Формула:
```
Recall = TP / (TP + FN)
```

Показує:
> яку частку позитивних прикладів модель знаходить

У спам-класифікації:
частка спаму, який було виявлено.

### Коли важлива
- медицина
- безпека
- виявлення шахрайства

Коли **FN дорожчі за FP**.

---

# False Positive Rate (FPR)
Частка негативних прикладів, помилково класифікованих як позитивні.

Формула:
```
FPR = FP / (FP + TN)
```

У спамі:
частка нормальних листів, помилково позначених як спам.

Ідеальна модель:
```
FPR = 0
```

---

# Precision (влучність)
Частка позитивних прогнозів, які справді позитивні.

Формула:
```
Precision = TP / (TP + FP)
```

У спамі:
частка листів, позначених як спам, які реально є спамом.

Ідеальна модель:
```
Precision = 1
```

---

# Precision vs Recall

Є компроміс:

- зменшення порогу → більше recall, менше precision
- збільшення порогу → більше precision, менше recall

```
менший threshold → FP↑ FN↓
більший threshold → FP↓ FN↑
```

---

# Як обирати метрику

## Accuracy
Використовувати:
- для збалансованих даних
- як загальний індикатор

Уникати:
- для незбалансованих даних

---

## Recall
Використовувати коли:
- важливо не пропустити позитивні приклади
- FN дуже дорогі

---

## FPR
Використовувати коли:
- FP дорогі
- важливо уникати хибних тривог

---

## Precision
Використовувати коли:
- позитивні прогнози повинні бути максимально точними

---

# Висновок
Метрика оцінювання залежить від задачі.

Найчастіше оптимізують:
- recall
- precision
- баланс між ними

Accuracy рідко достатня сама по собі.


# ROC і AUC

У попередніх розділах метрики (accuracy, recall, precision, FPR)
обчислювались для **одного порогового значення**.

Щоб оцінити модель **для всіх можливих порогів**, використовують:
- ROC-криву
- AUC

---

# ROC-крива (Receiver Operating Characteristic)

ROC-крива — це графік:

```
вісь X → FPR (False Positive Rate)
вісь Y → TPR (Recall)
```

Вона будується так:
1. змінюємо поріг класифікації
2. обчислюємо TPR і FPR
3. будуємо графік TPR проти FPR

ROC показує, як змінюється якість моделі при зміні порогу.

---

# Ідеальна модель
Ідеальна точка:
```
FPR = 0
TPR = 1
```

На ROC-графіку це:
```
(0, 1)
```

Крива проходить:
```
(0,0) → (0,1) → (1,1)
```

---

# Випадкова модель
ROC — діагональ:

```
(0,0) → (1,1)
```

Це означає:
- модель не краща за випадковість

---

# AUC (Area Under Curve)

AUC — це площа під ROC-кривою.

Вона інтерпретується як:

> ймовірність того, що модель поставить
> випадковий позитивний приклад вище за негативний.

---

# Інтерпретація AUC

```
AUC = 1.0 → ідеальна модель
AUC = 0.5 → випадкова модель
AUC < 0.5 → гірше випадковості
```

Приклад:
- AUC = 0.93 → дуже хороша модель
- AUC = 0.77 → нормальна модель
- AUC = 0.51 → майже випадкова

---

# Використання ROC та AUC

AUC зручно використовувати для:
- порівняння моделей
- оцінки ранжування прогнозів
- аналізу класифікатора без фіксованого порогу

---

# Вибір порогу за ROC

Найкращі пороги зазвичай розташовані
найближче до точки:

```
(0, 1)
```

Але вибір залежить від задачі.

---

# Компроміс порогу

Якщо FP дорогі:
→ обираємо менший FPR (лівий бік ROC)

Якщо FN дорогі:
→ обираємо більший TPR (верх ROC)

Якщо важливий баланс:
→ середня точка на кривій

---

# Висновок

ROC-крива:
- показує якість моделі для всіх порогів

AUC:
- узагальнена метрика якості класифікатора
- добре підходить для порівняння моделей



# Зсув прогнозування (Prediction Bias)

Зсув прогнозування — це різниця між:
- середнім значенням прогнозів моделі
- середнім значенням істинних міток

Формально:
```
Prediction bias = mean(predictions) − mean(labels)
```

---

# Приклад

Якщо в наборі даних:
```
5% листів — спам
```

то модель у середньому повинна прогнозувати:
```
0.05
```

Якщо:
```
mean(predictions) = 0.05
mean(labels) = 0.05
```

→ зсув прогнозування = 0  
→ модель узгоджена з даними.

---

# Ознака проблеми

Якщо модель прогнозує, наприклад:
```
50% спаму
```

у даних, де є лише:
```
5% спаму
```

це означає, що існує **упередженість прогнозу**.

---

# Можливі причини зсуву прогнозування

## 1. Проблеми з даними
- шум у даних
- неправильні мітки
- упереджена вибірка
- train/test distribution mismatch

---

## 2. Надмірна регуляризація
Модель стає занадто простою
і не може відобразити реальні залежності.

---

## 3. Помилки в pipeline
Наприклад:
- неправильне масштабування
- помилки preprocessing
- неправильний loss
- неправильні мітки

---

## 4. Недостатні ознаки
Модель не має достатньо інформації
для розв’язання задачі.

---

# Навіщо перевіряти prediction bias

Це:
- проста діагностика
- швидка перевірка якості моделі
- спосіб знайти проблеми з даними
- спосіб знайти проблеми з навчанням

---

# Висновок

Хороша модель має:
```
mean(predictions) ≈ mean(labels)
```

Зсув прогнозування — це швидкий індикатор того,
що модель або дані працюють неправильно.


# Багатокласова класифікація (Multiclass Classification)

Багатокласова класифікація — це розширення бінарної класифікації,
яке використовується, коли існує більше ніж два класи.

Якщо кожен приклад може належати лише одному класу,
таку задачу можна розкласти на кілька задач бінарної класифікації.

Цей підхід називають:
```
one-vs-rest (one-vs-all)
```

---

# Приклад

Нехай є три класи:
```
A, B, C
```

Можна побудувати класифікацію у два етапи:

## Крок 1
Бінарний класифікатор:
```
(A + B) vs C
```

## Крок 2
Другий класифікатор:
```
A vs B
```

---

# Приклад із реального життя

Класифікація рукописних цифр:

```
0, 1, 2, 3, 4, 5, 6, 7, 8, 9
```

Модель отримує зображення цифри
і визначає, до якого класу вона належить.

Це класична задача багатокласової класифікації.

---

# Класифікація з кількома мітками (Multi-label classification)

Якщо приклад може належати до кількох класів одночасно,
це вже інший тип задачі:

```
multi-label classification
```

Наприклад:
- фото може містити і "кіт", і "собака"
- текст може мати кілька тем

У цьому випадку класи не є взаємовиключними.

---

# Висновок

Багатокласова класифікація:
- більше двох класів
- кожен приклад належить лише одному класу

Multi-label класифікація:
- приклад може належати кільком класам одночасно



# Числові дані в машинному навчанні

Спеціалісти з машинного навчання витрачають значно більше часу
на оцінювання, очищення й перетворення даних, ніж на створення моделей.
Дані настільки важливі, що цьому аспекту присвячено кілька розділів:

- Робота із числовими даними
- Робота з категорійними даними
- Набори даних, узагальнення й перенавчання

---

## Числові дані

У цьому розділі розглядаються **числові дані** — це:
- цілі числа
- числа з рухомою комою

Вони поводяться як числа, тобто:
- їх можна додавати
- їх можна впорядковувати
- їх можна підраховувати
- між ними існують математичні співвідношення

---

## Приклади числових даних

- температура
- вага
- кількість оленів у природному заповіднику

---

## Категорійні дані

Деякі значення можуть виглядати як числа,
але насправді є **категоріями**.

Наприклад, поштові індекси США.

Поштовий індекс:
```
40004
```
не є "вдвічі більшим" за:
```
20002
```

Вони просто позначають різні географічні райони.

Тому такі значення вважаються:
```
категорійними даними
```

---

## Висновок

Числові дані:
- мають математичний зміст
- використовуються в обчисленнях

Категорійні дані:
- представляють групи або класи
- можуть виглядати як числа, але ними не є


# Числові дані: як модель отримує дані через векторні представлення ознак

Може здаватися, що модель машинного навчання безпосередньо використовує рядки з набору даних.
Насправді це не так.

Припустімо, що набір даних має п’ять стовпців, але лише два з них (b і d)
використовуються як ознаки. Модель не читає клітинки таблиці напряму.
Замість цього вона імпортує **масив чисел із рухомою комою**, який називається:

```
векторне представлення ознак
```

Цей вектор містить числові значення, що описують один приклад.

---

## Векторне представлення ознак

Векторне представлення ознак є посередником між:
- набором даних
- моделлю

Зазвичай воно **не містить необроблені значення з набору даних**.
Перед використанням дані перетворюються у форму, з якої модель може
ефективніше навчатися.

Наприклад, вектор ознак може виглядати так:

```
[0.13, 0.47]
```

---

## Конструювання ознак

Процес перетворення необроблених даних у вектор ознак називається:

```
конструювання ознак (feature engineering)
```

Це одна з найважливіших частин машинного навчання.

Найпоширеніші методи:

### Нормалізація
Перетворення чисел у значення зі стандартного діапазону.

### Групування (сегментація)
Перетворення чисел у діапазони або категорії.

---

## Числові та нечислові ознаки

У векторному представленні ознак **кожне значення повинно бути числом із рухомою комою**.

Однак багато ознак у наборах даних є:
- рядками
- категоріями
- іншими нечисловими значеннями

Тому важлива частина конструювання ознак — це
перетворення нечислових даних у числові представлення.

Ці методи детальніше розглядаються в наступних модулях.


# Числові дані: перші кроки

Перед створенням векторних представлень ознак рекомендується дослідити числові дані двома способами:

- візуалізувати дані;
- отримати статистику про дані.

---

## Візуалізація даних

Графіки допомагають знайти:
- аномалії
- закономірності
- помилки у даних

Перед початком аналізу створіть:
- точкові діаграми
- гістограми

Переглядайте графіки:
- на початку роботи з даними
- під час трансформації даних

Візуалізація допомагає постійно перевіряти припущення.

Для візуалізації зручно використовувати **pandas**.

Зверніть увагу: деякі інструменти візуалізації оптимізовані під певні формати даних.

---

## Статистичний аналіз даних

Окрім візуалізації, варто зібрати базову статистику:

- середнє значення
- медіана
- стандартне відхилення
- процентилі:
  - 0% (мінімум)
  - 25%
  - 50% (медіана)
  - 75%
  - 100% (максимум)

---

## Викиди (outliers)

**Викид** — це значення, яке сильно відрізняється від більшості інших.

Викиди можуть спричиняти проблеми під час навчання моделі, тому їх потрібно знаходити.

Ознака можливих викидів:
```
(25% − 0%) сильно відрізняється від (100% − 75%)
```

Важливо: навіть "нормальна" статистика не гарантує відсутність викидів.

---

## Типи викидів

### 1. Помилкові викиди
Причини:
- помилки введення даних
- збої інструментів збору даних

Такі значення зазвичай **видаляють**.

---

### 2. Реальні викиди
Це коректні дані, що відображають рідкісні випадки.

Як діяти:
- якщо модель повинна працювати з такими випадками → **залишити**
- якщо ні → **видалити або трансформувати**

Іноді викиди ознак відповідають викидам міток, тому можуть покращувати модель.

Однак надто екстремальні значення можуть зашкодити навчанню.

---

## Обробка викидів

Можливі підходи:
- видалення
- нормалізація
- обрізання (clipping)
- інші методи конструювання ознак



# Числові дані: нормалізація

Після дослідження даних за допомогою статистики та візуалізації їх потрібно трансформувати, щоб модель навчалася ефективніше.

**Мета нормалізації** — привести ознаки до подібного масштабу.

Наприклад:
- ознака X: від 154 до 24 917 482
- ознака Y: від 5 до 22

Після нормалізації обидві ознаки можуть мати діапазон, наприклад, **0–1**.

---

## Навіщо потрібна нормалізація

Нормалізація:

- прискорює збіжність навчання;
- покращує якість прогнозів;
- допомагає уникнути NaN через дуже великі значення;
- дозволяє моделі правильно визначати ваги ознак;
- запобігає домінуванню ознак із великим діапазоном.

Якщо ознаку нормалізовано під час навчання — її **обов’язково потрібно нормалізувати під час прогнозування**.

---

## Методи нормалізації

У цьому розділі розглядаються:

- лінійне масштабування
- масштабування за Z-оцінкою
- логарифмічне масштабування
- обрізання (clipping)

---

# Лінійне масштабування

Перетворює значення у стандартний діапазон:
- 0–1
- −1–1

### Коли використовувати
- межі значень стабільні
- мало викидів
- розподіл близький до рівномірного

### Приклад
Ознака **age**:
- діапазон приблизно 0–100
- мало викидів
- добре підходить для лінійного масштабування

> У реальних задачах частіше використовують Z-масштабування.

---

# Масштабування за Z-оцінкою

Z-значення показує, на скільки стандартних відхилень число відрізняється від середнього.

Після нормалізації:
- середнє = 0
- стандартне відхилення = 1

### Коли використовувати
- дані мають нормальний або близький до нормального розподіл

Якщо є екстремальні викиди — можна поєднувати з обрізанням.

---

# Логарифмічне масштабування

Застосовується логарифм (зазвичай натуральний):

```
ln(x)
```

### Коли використовувати
Для **степеневих розподілів** (long tail).

Приклади:
- кількість рейтингів фільмів
- продажі книг
- популярність контенту
- доходи
- кількість підписників

Приклад:
```
ln(100) ≈ 4.6
ln(1,000,000) ≈ 13.8
```

Різниця стає значно меншою, що допомагає моделі навчатися.

---

# Обрізання (clipping)

Метод зменшення впливу екстремальних викидів.

Ідея:
обмежити значення зверху або знизу.

Наприклад:
```
roomsPerPerson ≤ 4
```

Усі значення більше 4 замінюються на 4.

Обрізання можна застосовувати:
- до сирих даних
- після Z-нормалізації

Наприклад:
```
Z > 3  →  3
Z < -3 → -3
```

Обрізання не ігнорує дані, а лише зменшує їх вплив.

Використовувати обережно — іноді викиди важливі.

---

# Коротке резюме

| Метод | Коли використовувати |
|------|----------------------|
| Лінійне масштабування | рівномірний розподіл, мало викидів |
| Z-масштабування | нормальний розподіл |
| Логарифмічне масштабування | степеневий розподіл |
| Обрізання | екстремальні викиди |

---

## Головна ідея
Найкращий метод нормалізації — той, який добре працює для конкретного набору даних.


# Числові дані: групування

**Групування (сегментація)** — це метод конструювання ознак, який об’єднує числові значення в піддіапазони (сегменти). Часто це перетворює числову ознаку на **категорійну**.

Наприклад, якщо ознака X має значення від 15 до 425, можна створити сегменти:

- Секція 1: 15–34
- Секція 2: 35–117
- Секція 3: 118–279
- Секція 4: 280–392
- Секція 5: 393–425

Тоді значення X представляється **one-hot-вектором**.

| Секція | Діапазон | Вектор |
|--------|----------|--------|
| 1 | 15–34 | [1,0,0,0,0] |
| 2 | 35–117 | [0,1,0,0,0] |
| 3 | 118–279 | [0,0,1,0,0] |
| 4 | 280–392 | [0,0,0,1,0] |
| 5 | 393–425 | [0,0,0,0,1] |

Модель запам’ятовує **окрему вагу для кожного сегмента**.

---

## Коли групування корисне

Групування — хороша альтернатива масштабуванню або обрізанню, якщо:

- лінійний зв’язок між ознакою і міткою слабкий або відсутній;
- значення ознаки утворюють **кластери**.

---

# Приклад: температура і кількість покупців

Модель прогнозує кількість покупців за температурою.

На графіку видно **три кластери температур**:

- 4–11
- 12–26
- 27–36

Замість однієї числової ознаки температури можна створити **3 сегменти**, і модель навчиться окремих ваг для кожного діапазону.

Це краще, ніж використовувати температуру як одне числове значення, якщо залежність **нелінійна**.

---

## Скільки сегментів створювати

Занадто багато сегментів — погано:

- у сегменті може бути замало прикладів;
- зростає кількість ознак;
- модель може перенавчатися.

Зазвичай сегментів має бути **небагато, але достатньо для навчання**.

---

# Квантильна сегментація

**Квантильна сегментація** створює сегменти так, щоб у кожному було приблизно однакова кількість прикладів.

Це допомагає:
- уникати порожніх сегментів;
- зменшити вплив викидів;
- стабілізувати навчання.

---

## Приклад

Якщо сегменти ціни автомобілів зробити однакової ширини:
- дешеві авто → багато прикладів
- дорогі авто → мало прикладів

Квантильна сегментація:
- робить сегменти **різної ширини**
- але з **однаковою кількістю прикладів**

---

# Висновок

Групування:
- перетворює числові ознаки на категорійні;
- дозволяє моделі вивчати **нелінійні залежності**;
- корисне для **кластеризованих даних**.

Квантильна сегментація:
- забезпечує приблизно однакову кількість прикладів у кожному сегменті;
- зменшує вплив нерівномірних розподілів.


## Числові дані: групування

Групування (інша назва – сегментація) – це метод конструювання ознак, який об’єднує різні числові піддіапазони в секції або сегменти. У багатьох випадках групування перетворює числові дані на категорійні. Наприклад, розгляньмо ознаку X, мінімальне й максимальне значення якої становлять 15 і 425 відповідно. Використовуючи групування, можна представити X як п’ять секцій.

Секція 1: 15–34  
Секція 2: 35–117  
Секція 3: 118–279  
Секція 4: 280–392  
Секція 5: 393–425  

Секція 1 охоплює діапазон 15–34, тому кожне значення X від 15 до 34 потрапляє в неї. Модель, навчена на цих секціях, реагуватиме однаково на значення X 17 і 29, оскільки обидва містяться в секції 1.

Вектор ознак утворює п’ять секцій, наведених нижче.

| Номер секції | Діапазон | Вектор ознак |
|-------------|---------|--------------|
| 1 | 15–34 | [1.0, 0.0, 0.0, 0.0, 0.0] |
| 2 | 35–117 | [0.0, 1.0, 0.0, 0.0, 0.0] |
| 3 | 118–279 | [0.0, 0.0, 1.0, 0.0, 0.0] |
| 4 | 280–392 | [0.0, 0.0, 0.0, 1.0, 0.0] |
| 5 | 393–425 | [0.0, 0.0, 0.0, 0.0, 1.0] |

Навіть якщо X у наборі даних представлено одним стовпцем, через групування модель розглядає X як п’ять окремих ознак. Тому модель запам’ятовує окремі значення ваги для кожної секції.

Групування – хороша заміна масштабуванню або обрізанню, якщо виконується будь-яка з умов:
- Загальний лінійний зв’язок між ознакою і міткою слабкий або відсутній.
- Значення ознак кластеризовано.

---

## Приклад групування: кількість покупців залежно від температури

Уявімо, що ви створюєте модель, яка прогнозує кількість покупців за даними про температуру на вулиці.

Можна виділити три кластери температур:

Секція 1: 4–11  
Секція 2: 12–26  
Секція 3: 27–36  

Модель запам’ятовує окремі значення ваги для кожної секції.

Часто не варто створювати занадто багато секцій, тому що:
- у секції може бути недостатньо прикладів для навчання;
- збільшується кількість ознак.

---

## Квантильна сегментація

Квантильна сегментація розмежовує сегменти так, щоб кількість прикладів у кожному з них була приблизно однаковою, і здебільшого приховує викиди.

Це дозволяє уникнути ситуації, коли:
- у деяких сегментах дуже багато даних;
- у інших сегментах майже немає прикладів для навчання.

---

## Числові дані: очищення

Як спеціаліст із машинного навчання ви витрачатимете багато часу на очищення даних. Навіть кілька поганих прикладів можуть зіпсувати набір даних.

Поширені проблеми з даними:

| Категорія проблеми | Приклад |
|-------------------|--------|
| Пропущені значення | Не записано вік особи |
| Повторювані приклади | Логи завантажені двічі |
| Значення поза діапазоном | Зайва цифра під час введення |
| Неправильні мітки | Дуб позначено як клен |

Можна написати програму для виявлення:
- пропущених значень;
- повторюваних прикладів;
- значень поза допустимим діапазоном.

Наприклад, якщо температура повинна бути в межах **10–30°C**, програма має виявляти всі значення поза цим діапазоном.


## Числові дані: якості хороших числових ознак

У цьому модулі ми розглянули способи перетворення необроблених даних у відповідні векторні представлення ознак. Хороші числові ознаки мають якості, описані в цьому розділі.

### Мають чітку назву

Значення кожної ознаки має бути чітке, розумне й очевидне для будь-якої людини, що працює над проектом. Наприклад, значення ознаки, наведеної нижче, не зрозуміле.

**Не рекомендовано**
```
house_age: 851472000
```

Натомість назва й значення ознаки, наведеної нижче, набагато зрозуміліші.

**Рекомендовано**
```
house_age_years: 27
```

Примітка: хоча заплутані назви ознак можуть ускладнювати роботу людям, для моделі це не має значення (якщо значення правильно нормалізовані).

---

### Пройшли перевірку або тестування перед навчанням

Іноді до незрозумілих значень призводять неправильні дані, а не хибні рішення розробників. Наприклад, ознаку `user_age_in_years` отримано з джерела, яке не перевіряло значення.

**Не рекомендовано**
```
user_age_in_years: 224
```

Але вік людини може бути:

**Рекомендовано**
```
user_age_in_years: 24
```

Перевіряйте дані перед навчанням моделі.

---

### Є розумними

"Магічне значення" — це навмисний розрив у неперервній ознаці. Наприклад, ознака `watch_time_in_seconds` може містити значення від 0 до 30, але значення `-1` означає відсутність вимірювання.

**Не рекомендовано**
```
watch_time_in_seconds: -1
```

Модель намагатиметься інтерпретувати це як реальне значення, що може погіршити якість прогнозів.

Кращий підхід — створити окрему логічну ознаку:

**Рекомендовано**
```
watch_time_in_seconds: 4.82
is_watch_time_in_seconds_defined: True
```

```
watch_time_in_seconds: 0
is_watch_time_in_seconds_defined: False
```

---

Для дискретної числової ознаки, значення якої належать до скінченного набору, відсутні значення можна позначити окремим числом із цього набору. У такому випадку модель зможе навчитися окремих ваг для кожного можливого значення, включно зі значенням, що означає відсутність даних.



## Числові дані: поліноміальні перетворення

Іноді, коли фахівець із машинного навчання володіє галузевими знаннями, які дають змогу припустити, що одна змінна пов’язана з іншою, піднесеною до степеня (квадрат, куб тощо), корисно створити синтетичну ознаку на основі однієї з наявних числових ознак.

Розгляньмо розподіл точок даних, де один клас позначено колами, а інший — трикутниками. У такому випадку неможливо провести пряму лінію, яка б чітко розділяла ці два класи, але це можна зробити кривою, наприклад:
  
y = x²

Як зазначалося в модулі лінійної регресії, лінійну модель з однією ознакою можна описати рівнянням:

y = w₀ + w₁x

Додаючи нові ознаки, рівняння розширюється:

y = w₀ + w₁x + w₂x² + ...

Градієнтний спуск знаходить ваги, що мінімізують функцію втрат. Якщо дані не можна розділити прямою, можна зберегти лінійну модель, але додати нову синтетичну ознаку:

x² = x * x

Це називається **поліноміальним перетворенням**. Модель все ще залишається лінійною відносно параметрів, але може моделювати нелінійні залежності.

Оновлена модель виглядає так:

y = w₀ + w₁x + w₂x²

У цьому випадку модель може розділяти дані за допомогою кривої.

Зазвичай поліноміальне перетворення створюють піднесенням числової ознаки до степеня. Часто вибір степеня базується на знаннях предметної області. Наприклад, квадратична залежність зустрічається у фізичних процесах:
- прискорення під дією гравітації,
- загасання світла або звуку з відстанню,
- пружна потенційна енергія.

Споріднене поняття для категорійних даних — **поєднання ознак**, що створюється шляхом комбінування двох різних ознак.


## Робота з категорійними даними

**Орієнтовна тривалість модуля:** 50 хв

### Навчальні цілі
- Розрізняти категорійні й числові дані.
- Представляти категорійні дані за допомогою векторів унітарного кодування.
- Розглянути поширені проблеми, які виникають із категорійними даними.
- Створювати поєднання ознак.

### Вимоги
Передбачається, що всі, хто проходить цей модуль, знайомі з поняттями з модулів:
- Вступ до машинного навчання
- Робота із числовими даними

---

## Категорійні дані

Категорійні дані мають певний набір можливих значень. Наприклад:
- різні види тварин у національному парку;
- назви вулиць у певному місті;
- чи є електронний лист спамом;
- кольори фасадів будинків;
- сегментовані числа з модуля про числові дані.

---

## Числа також можуть бути категорійними даними

Справжні числові дані можна змістовно множити. Наприклад, якщо модель прогнозує вартість будинку за площею, то за інших рівних умов будинок площею 200 м² має коштувати приблизно вдвічі більше, ніж будинок площею 100 м².

Однак деякі ознаки з цілими числами краще представляти як категорійні. Наприклад, **поштовий індекс**.

Якщо представити поштовий індекс як числову ознаку, модель може помилково припустити існування числової залежності між індексами. Наприклад, що індекс 20004 «удвічі більший сигнал», ніж 10002.

Якщо ж представити поштові індекси як категорійні дані, модель зможе навчитися окремим вагам для кожного значення.

---

## Кодування

**Кодування** — це перетворення категорійних або інших даних на числові вектори, на яких модель може навчатися.

Це необхідно, тому що моделі машинного навчання працюють лише зі значеннями з рухомою комою. Текстові значення, такі як:
- `"dog"`
- `"maple"`

не можуть використовуватися безпосередньо.

У цьому модулі розглядаються різні методи кодування категорійних даних.



## Категорійні дані: словник і унітарне кодування

Термін **вимір** — це кількість елементів у векторному представленні ознак. Деякі категорійні ознаки є низьковимірними.

| Назва ознаки | Кількість категорій | Приклади категорій |
|--------------|--------------------|--------------------|
| snowed_today | 2 | істина, хиба |
| skill_level | 3 | початківець, досвідчений спеціаліст, експерт |
| season | 4 | зима, весна, літо, осінь |
| day_of_week | 7 | понеділок, вівторок, середа |
| planet | 8 | Меркурій, Венера, Земля |

Якщо категоріальна ознака має невелику кількість можливих значень, її можна кодувати за допомогою **словника**. У цьому випадку модель розглядає кожне можливе значення як окрему ознаку та вивчає для нього власну вагу.

---

## Індексація

Моделі машинного навчання можуть працювати лише з числами з рухомою комою, тому рядкові значення потрібно перетворити на індекси.

Наприклад:
```
Red → 0
Orange → 1
Blue → 2
Yellow → 3
Green → 4
Black → 5
Purple → 6
Brown → 7
```

Однак модель **не повинна навчатися безпосередньо на індексах**, тому що вони створюють хибний порядок між категоріями.

---

## Унітарне кодування (One-Hot Encoding)

В унітарному кодуванні:
- кожну категорію представляє вектор довжини N;
- лише один елемент дорівнює 1.0;
- інші елементи дорівнюють 0.0.

Приклад для ознаки `car_color`:

| Категорія | Вектор |
|----------|--------|
| Red | [1,0,0,0,0,0,0,0] |
| Orange | [0,1,0,0,0,0,0,0] |
| Blue | [0,0,1,0,0,0,0,0] |
| Yellow | [0,0,0,1,0,0,0,0] |
| Green | [0,0,0,0,1,0,0,0] |
| Black | [0,0,0,0,0,1,0,0] |
| Purple | [0,0,0,0,0,0,1,0] |
| Brown | [0,0,0,0,0,0,0,1] |

У модель передається саме цей вектор, а не текст або індекс.

---

## Розріджене представлення

Багато категорійних ознак є **розрідженими**, тобто більшість значень дорівнюють нулю.

Наприклад:
```
Blue → [0,0,1,0,0,0,0,0]
```

Розріджене представлення:
```
2
```

Це означає, що одиниця знаходиться на позиції 2.

Для множинної активації:
```
Blue + Black → 2, 5
```

---

## Викиди в категорійних даних

Рідкісні категорії (наприклад, `"Mauve"` або `"Avocado"`) можна об’єднати в одну категорію:
```
OOV (out-of-vocabulary)
```

Модель вивчає одну вагу для цієї групи.

---

## Високовимірні категорійні ознаки

| Ознака | Кількість категорій | Приклади |
|--------|--------------------|----------|
| words_in_english | ~500 000 | "happy", "walking" |
| US_postal_codes | ~42 000 | 02114 |
| last_names_in_Germany | ~850 000 | "Schmidt" |

Для таких ознак **унітарне кодування неефективне**.

Замість нього використовують:
- векторні представлення (embeddings)
- хешування (hash trick)

Переваги зменшення вимірності:
- швидше навчання моделі
- швидші прогнози





 ## Робота з числовими даними

Спеціалісти з машинного навчання витрачають набагато більше часу на оцінювання, очищення й перетворення даних, ніж на створення моделей. Дані настільки важливі, що цьому аспекту в курсі присвячено цілих три розділи:

* "Робота із числовими даними" (цей модуль)
* Робота з категорійними даними
* Набори даних, узагальнення й перенавчання

У цьому розділі розглядаються числові дані, тобто цілі числа або значення з рухомою комою, які поводяться як числа: вони адитивні, злічувані, упорядковані тощо. Наступний модуль присвячено категоріальним даним, які можуть містити числа, що поводяться як категорії. З третього модуля ви дізнаєтеся, як підготувати дані так, щоб забезпечити якісні результати на етапах навчання й оцінювання моделі.

### Приклади числових даних

* температура
* вага
* кількість оленів, що зимують у природному заповіднику

На відміну від них, поштові індекси США хоч і є п’яти- або дев’ятизначними числами, але не поводяться як такі й не відображають математичні співвідношення. Поштовий індекс 40004 (округ Нельсон, штат Кентуккі) не вдвічі більший кількісно за поштовий індекс 20002 (Вашингтон, округ Колумбія). Ці числа представляють категорії (географічні райони) і вважаються категорійними даними.

---

## Категорійні дані: типові проблеми

Числові дані часто записуються за допомогою наукових приладів або автоматизованих вимірювань. А категорійні дані часто класифікують люди або моделі машинного навчання. Те, хто визначає категорії і мітки та як такі рішення приймаються, впливає на надійність і корисність даних.

### Спеціалісти з оцінювання

Дані, які вручну розмітили люди, часто називають **золотими мітками**. Вони вважаються бажанішими для навчальних моделей, ніж дані з машинними мітками, через відносно кращу якість.

Це не завжди означає, що будь-який набір даних із мітками, які додали люди, має високу якість. На дані можуть вплинути людські помилки, упередженість і злий умисел під час збирання або очищення й обробки. Перевірте дані на наявність згаданих факторів перед навчанням.

Будь-які дві людини можуть по-різному позначити один і той самий приклад. Різниця між рішеннями спеціалістів з оцінювання називається **погодження між оцінювачами**. Отримати уявлення про розбіжності можна, залучивши кількох оцінювачів для обробки одного прикладу й вимірявши рівень погодження між ними.

### Машинне оцінювання

Дані, які розмітила машина, часто називають **срібними мітками**. Такі дані можуть значно відрізнятися за якістю. Їх потрібно перевіряти на точність, упередженість і відповідність реальності.

Наприклад, якщо модель комп’ютерного зору плутає чихуахуа з кексом, або аналізатор настроїв надає нейтральним словам негативний бал, це може погіршити якість набору даних і моделі.

### Висока розмірність

Категорійні дані часто створюють **високовимірні векторні представлення ознак**, що збільшує витрати на навчання. Через це часто застосовують методи **зменшення розмірності**.

Для текстових даних основним підходом є перетворення ознак у **векторні представлення (embeddings)**.

---

## Категорійні дані: поєднання ознак

**Поєднання ознак** створюються шляхом декартового добутку двох або більше категорійних чи сегментованих ознак. Вони дозволяють лінійним моделям враховувати **нелінійності** та **взаємодію ознак**.

### Приклад

Ознаки листя:

* edges: smooth, toothed, lobed
* arrangement: opposite, alternate

Лист із краями smooth і розташуванням opposite:

```
{(1, 0, 0), (1, 0)}
```

Поєднання ознак:

```
{
Smooth_Opposite,
Smooth_Alternate,
Toothed_Opposite,
Toothed_Alternate,
Lobed_Opposite,
Lobed_Alternate
}
```

Приклад обчислення:

```
Smooth_Opposite = edges[0] * arrangement[0]
Toothed_Opposite = edges[1] * arrangement[0]
Lobed_Alternate = edges[2] * arrangement[1]
```

Для листя дуба (lobed + alternate):

```
{0, 0, 0, 0, 0, 1}
```

### Коли використовувати поєднання ознак

Знання предметної області допомагає знаходити корисні комбінації ознак. Нейронні мережі також можуть автоматично знаходити такі взаємодії під час навчання.

⚠️ Важливо: поєднання розріджених ознак створює **ще більш розріджені ознаки**.
Наприклад:

* A має 100 елементів
* B має 200 елементів
* A × B → 20 000 елементів



## Набори даних: характеристики даних

Набір даних — це колекція прикладів.

Багато наборів зберігають дані в таблицях (сітках), наприклад у форматі CSV, електронних таблицях або таблицях баз даних. Таблиці є інтуїтивно зрозумілим форматом для моделей машинного навчання:

* кожен рядок — це приклад
* кожен стовпець — ознака або мітка

Набори даних також можуть походити з інших джерел, наприклад із файлів журналів або буферів протоколів.

Ефективність моделі машинного навчання безпосередньо залежить від якості даних, на яких її тренують.

---

## Типи даних

У наборі даних можуть бути різні типи інформації:

* числові дані
* категорійні дані
* текст (людська мова)
* мультимедійні дані (зображення, відео, аудіо)
* вихідні дані інших ML-систем
* вектори ембедингів

---

## Кількість даних

Загальне правило: кількість навчальних прикладів має бути **у 10–20 разів більшою за кількість параметрів моделі**. На практиці хороші моделі зазвичай потребують ще більше даних.

Моделі, навчені на **великих наборах даних із невеликою кількістю ознак**, часто працюють краще, ніж моделі з великою кількістю ознак і малим набором даних.

Для різних задач потрібна різна кількість прикладів:

* іноді достатньо десятків прикладів
* іноді навіть трильйона може бути замало

Невеликі набори даних можуть бути ефективними для **адаптації вже навченої моделі (transfer learning)**.

---

## Якість і надійність даних

Високоякісний набір даних дозволяє моделі давати правильні результати.
Низькоякісний — заважає моделі працювати.

**Надійність даних** — це ступінь довіри до них.

Питання для перевірки надійності:

* Як часто трапляються помилки в мітках?
* Чи є шум у значеннях ознак?
* Чи правильно відфільтровані дані для задачі?

Типові проблеми:

* пропущені значення
* дублікати прикладів
* неправильні значення ознак
* неправильні мітки
* пошкоджені або нестабільні ділянки даних

Рекомендується використовувати автоматичні перевірки даних (валідацію схем, діапазонів значень тощо).

---

## Повні й неповні приклади

**Повний приклад** містить значення для всіх ознак.
**Неповний приклад** має хоча б одне пропущене значення.

Не варто навчати модель на неповних прикладах. Можна:

* видалити неповні приклади
* імпутувати відсутні значення

---

## Імпутація

Імпутація — це заповнення пропущених значень обґрунтованими оцінками.

Поширений підхід:

* використання середнього значення
* використання медіани
* для Z-оцінок — значення 0

Правильна імпутація може покращити модель, неправильна — погіршити її.

Якщо складно вирішити, що краще:

1. створіть набір даних без неповних прикладів
2. створіть набір із імпутацією
3. порівняйте результати моделей

Після імпутації **перемішайте порядок прикладів** перед навчанням.

---

## Приклад

Відсортований набір даних:

| Позначка часу        | Температура |
| -------------------- | ----------- |
| 8 червня 2023, 09:00 | 12          |
| 8 червня 2023, 10:00 | 18          |
| 8 червня 2023, 11:00 | немає       |
| 8 червня 2023, 12:00 | 24          |
| 8 червня 2023, 13:00 | 38          |



## Набори даних: мітки

У цьому розділі йдеться про мітки.

---

## Прямі й проксі-мітки

Розгляньмо два типи міток.

**Прямі мітки** ідентичні прогнозу, який має зробити модель. Такий прогноз уже є у наборі даних як окремий стовпець.
Наприклад, стовпець `bicycle owner` є прямою міткою для моделі бінарної класифікації, що визначає, чи має людина велосипед.

**Проксі-мітки** подібні до прогнозу, але не є його точним відображенням.
Наприклад, передплата журналу *Bicycle Bizarre* може вказувати на наявність велосипеда, але не гарантує цього.

Зазвичай **прямі мітки кращі за проксі-мітки**, але вони не завжди доступні.

Проксі-мітки — це компроміс. Їхня корисність залежить від того, **наскільки сильно вони пов’язані з реальним прогнозом**.

Іноді пряма мітка існує, але її складно представити як числове значення. У такому випадку використовують проксі-мітку.

---

## Приклад

Завдання компанії:
надіслати купони власникам велосипедів.

Завдання моделі:
визначити, чи має людина велосипед.

У наборі даних немає стовпця `bike owner`, але є стовпець
`recently bought a bicycle`.

Це може бути **досить хорошою проксі-міткою**, оскільки люди, які нещодавно купили велосипед, з великою ймовірністю його мають.

---

## Дані, створені людиною

Деякі мітки створюють люди (спеціалісти з оцінювання).
Наприклад, метеорологи можуть визначати типи хмар за зображеннями.

Інші мітки створюються автоматично програмним забезпеченням або моделями машинного навчання.

---

## Переваги людських міток

* люди можуть виконувати складні завдання, недоступні моделям
* змушують створювати чіткі критерії оцінювання

---

## Недоліки людських міток

* висока вартість
* можливість помилок
* іноді потрібна оцінка кількох спеціалістів

---

## Важливі запитання

Перед створенням міток варто визначити:

* Яка кваліфікація потрібна оцінювачам?
* Скільки прикладів потрібно?
* Як швидко потрібні мітки?
* Який бюджет доступний?

---

## Перевірка якості міток

Рекомендується перевіряти роботу спеціалістів з оцінювання:

* самостійно розмітити частину даних
* порівняти результати
* уточнити інструкції у разі розбіжностей

Не варто автоматично вважати власні мітки правильними, особливо коли йдеться про суб’єктивні оцінки.




## Набори даних: незбалансовані набори

Розгляньмо набір даних із міткою категорії, значення якої може бути **позитивним** або **негативним**.

У **збалансованому наборі даних** кількість позитивних і негативних міток приблизно однакова.
Якщо одна мітка зустрічається значно частіше, набір даних вважається **незбалансованим**.

* частіша мітка → **клас більшості**
* рідкісна мітка → **клас меншості**

---

## Рівні незбалансованості

| Частка класу меншості | Рівень незбалансованості |
| --------------------- | ------------------------ |
| 20–40%                | Незначний                |
| 1–20%                 | Помірний                 |
| < 1%                  | Надзвичайний             |

Наприклад, у наборі даних для **виявлення вірусів**:

* клас меншості: 0,5%
* клас більшості: 99,5%

Такі набори часто трапляються в медицині.

---

## Проблема незбалансованості

У незбалансованих наборах даних моделі часто:

* отримують **замало прикладів класу меншості**
* навчаються переважно на **класі більшості**

Наприклад, якщо **batch size = 50**, у пакеті може не бути жодного позитивного прикладу.

Спочатку варто **спробувати навчити модель на оригінальному наборі даних**.
Якщо результат незадовільний — застосовують спеціальні методи.

---

## Зменшення вибірки й збільшення ваги

### Зменшення вибірки (undersampling)

Навчання на **меншій підмножині прикладів класу більшості**.

Приклад:
було 200 негативних і 1 позитивний → співвідношення 0,5%.

Після зменшення вибірки у 10 разів:

* 20 негативних
* 1 позитивний
* співвідношення ≈ 5%

---

### Збільшення ваги (reweighting)

Після зменшення вибірки потрібно **збільшити вагу прикладів**, вибірку яких зменшено.

Якщо вибірку зменшено у 10 разів:

```
weight = 10
```

Це означає, що під час обчислення функції втрат:

* приклад із вагою 10
* у 10 разів важливіший за приклад із вагою 1.

Ця вага **не є параметром моделі** — це вага навчальних прикладів.

Збільшення ваги допомагає:

* зменшити зміщення прогнозів
* зберегти статистичний баланс даних

---

## Коефіцієнти перебалансування

Оптимальний коефіцієнт залежить від:

* розміру пакета (batch size)
* коефіцієнта незбалансованості
* кількості навчальних прикладів

Важливо:
у кожному пакеті має бути **достатньо прикладів класу меншості**.

Рекомендація:

```
batch_size ≥ кілька × коефіцієнт незбалансованості
```

Наприклад:

```
незбалансованість = 100:1
batch_size ≥ 500
```



## Набори даних: розділення первинного набору

У всіх хороших проєктах із розробки програмного забезпечення передбачено багато часу на тестування. Те саме стосується й машинного навчання — модель потрібно тестувати, щоб визначити, наскільки правильні її прогнози.

---

## Набори даних для навчання, перевірки й тестування

Модель слід оцінювати на прикладах, які **відрізняються від тих, що використовувалися для навчання**.
Для цього первинний набір даних розділяють на підмножини.

Мінімальний варіант:

* **навчальний набір (training set)** — для навчання моделі;
* **тестовий набір (test set)** — для фінального оцінювання.

Типовий поділ:

* ~80% — навчання
* ~20% — тестування

Однак кращим підходом є використання **трьох підмножин**:

* **навчальний набір** — навчання моделі;
* **набір для перевірки (validation set)** — налаштування моделі;
* **тестовий набір** — фінальна перевірка.

Типовий розподіл:

* 70% — навчання
* 15% — перевірка
* 15% — тестування

---

## Робочий процес

1. Навчити модель на навчальному наборі.
2. Оцінити модель на наборі для перевірки.
3. Скоригувати модель:

   * змінити гіперпараметри,
   * додати або видалити ознаки,
   * змінити архітектуру моделі.
4. Повторювати кроки 1–3.
5. Використати **тестовий набір лише для фінального підтвердження результату**.

---

## Важливе правило

Якщо ви трансформуєте ознаки в навчальному наборі, **таку саму трансформацію потрібно застосувати** до:

* validation-набору,
* test-набору,
* реальних даних.

---

## “Зношування” тестових і validation-даних

Якщо багато разів використовувати ті самі validation або test дані для прийняття рішень, модель може **неявно підлаштуватися під них**.

Через це:

* результати виглядатимуть кращими, ніж є насправді;
* модель може гірше працювати на нових даних.

Рішення:

* періодично збирати нові дані;
* оновлювати validation і test набори.

---

## Типові проблеми

### Повторювані приклади

Одна з найпоширеніших помилок — наявність однакових прикладів у:

* навчальному наборі
* тестовому наборі

У цьому випадку оцінювання стає некоректним, бо модель фактично бачила тестові дані під час навчання.

Перед розділенням набору даних слід:

* видалити дублікати,
* переконатися, що test і validation не містять прикладів із training.

---

## Вимоги до хорошого тестового або validation-набору

Хороший набір даних для оцінювання:

* достатньо великий для статистично значущих результатів;
* репрезентує загальний набір даних;
* відображає реальні дані, з якими працюватиме модель;
* не містить прикладів із навчального набору.



## Набори даних: розділення первинного набору

У всіх хороших проектах із розробки програмного забезпечення передбачено багато часу на тестування додатків. Тому й ми наполегливо рекомендуємо протестувати вашу модель машинного навчання, щоб визначити, наскільки її прогнози правильні.

### Набори даних для навчання, перевірки й тестування

Варто протестувати модель на наборі прикладів, відмінних від тих, що використовуються для її навчання. У машинному навчанні традиційно отримують різні приклади, розділяючи первинний набір даних.

Первинний набір даних зазвичай ділять на:

* **навчальний набір** — для тренування моделі;
* **набір для перевірки (validation)** — для налаштування моделі;
* **тестовий набір** — для фінального оцінювання.

Типовий розподіл:

* 70% — навчальний набір
* 15% — набір для перевірки
* 15% — тестовий набір

### Робочий процес

1. Тренування моделі на навчальному наборі.
2. Оцінювання на наборі для перевірки.
3. Коригування моделі (гіперпараметри, ознаки, архітектура).
4. Повторення кроків 1–3.
5. Фінальна перевірка на тестовому наборі.

> Коли ви трансформуєте ознаки в навчальному наборі, потрібно застосувати ті самі трансформації до наборів перевірки й тестування.

### Проблема "зношування" наборів

Якщо занадто часто використовувати ті самі набори перевірки або тестування для прийняття рішень, модель може неявно пристосуватися до них. У такому випадку бажано зібрати нові дані.

### Типові проблеми з тестовими наборами

Наприклад, модель для виявлення спаму може показувати **99% точності**, якщо:

* у навчальному й тестовому наборах є **однакові приклади**;
* дублікати не були видалені перед розділенням даних.

Це означає, що модель фактично бачила тестові дані під час навчання.

### Хороший тестовий або validation-набір має бути:

* достатньо великим для статистично значущих результатів;
* репрезентативним для всього набору даних;
* схожим на реальні дані, з якими працюватиме модель;
* без прикладів із навчального набору.

---

## Набори даних: перетворення даних

Моделі машинного навчання можуть навчатися лише на **значеннях із рухомою комою**. Тому ознаки потрібно перетворювати.

Наприклад:

* назви вулиць — це рядки ("Бродвей");
* їх потрібно перетворити на числове представлення.

### Нормалізація

Більшість числових ознак також потрібно трансформувати.
Це називається **нормалізацією** — приведенням значень до обмеженого діапазону, що покращує навчання моделі.

### Вибірка даних

Якщо даних занадто багато:

* можна взяти **підмножину прикладів** для навчання;
* бажано, щоб вона була **релевантною для задачі прогнозування**.

### Конфіденційність

Із наборів даних слід видаляти:

* ідентифікаційну інформацію;
* персональні дані.

Це допомагає захистити конфіденційність користувачів.



## Перенавчання

**Перенавчання (overfitting)** означає створення моделі, яка настільки точно відповідає навчальному набору даних (фактично запам’ятовує його), що не може робити правильні прогнози на нових даних. Перенавчена модель подібна до винаходу, який добре працює в лабораторії, але нічого не вартий у реальному світі.

> Перенавчання — поширена проблема машинного навчання.

Наприклад, модель може дуже точно класифікувати приклади з навчального набору, але показувати погані результати на тестовому наборі. Це і є класичний випадок перенавчання.

---

## Оптимальне навчання, перенавчання й недонавчання

Мета — створити модель, яка добре працює на **нових даних**.

* **Недонавчання (underfitting)** — модель працює погано навіть на навчальних даних.
* **Оптимальне навчання** — модель добре узагальнює нові дані.
* **Перенавчання (overfitting)** — модель добре працює на навчальних даних, але погано на нових.

**Узагальнення (generalization)** — це здатність моделі робити якісні прогнози на нових даних.

---

## Виявлення перенавчання

Перенавчання можна виявити за допомогою:

* **кривих втрат (loss curves)**;
* **кривих узагальнення (learning / generalization curves)**.

Типова ознака перенавчання:

* втрати на навчальному наборі зменшуються;
* втрати на наборі для перевірки починають зростати після певної кількості ітерацій.

Якщо криві втрат для навчального та validation-набору мають подібну форму — модель узагальнює добре.

---

## Причини перенавчання

Найпоширеніші причини:

* навчальний набір **погано відображає реальні дані**;
* **модель занадто складна**.

---

## Передумови узагальнення

Щоб модель добре узагальнювала, набір даних має відповідати таким умовам:

* приклади **незалежні й однаково розподілені (i.i.d.)**;
* набір даних **стаціонарний** (розподіл не змінюється суттєво з часом);
* навчальний, validation і тестовий набори мають **подібний статистичний розподіл**;
* тестовий набір є **проксі реальних даних**.

---

## Практичні висновки

Щоб уникнути перенавчання:

* перемішуйте дані перед розділенням;
* використовуйте validation-набір;
* не робіть модель надто складною;
* збирайте більше даних;
* перевіряйте модель на даних, схожих на реальні.

---

## Приклади ситуацій

**Зміна смаків глядачів у потоковому сервісі** може призвести до проблем, тому що:

* розподіл даних змінюється з часом.

**Модель, навчена на погодних даних за один рік**, може працювати, якщо:

* навчальний, validation і тестовий набори містять дані з усіх сезонів.

**Динамічне ціноутворення квитків** — складний випадок, тому що:

* дані залежать від часу;
* ціни змінюються залежно від кількості місць;
* розподіл даних може змінюватися.



## Надмірне навчання: складність моделі

У попередньому розділі розглядалася модель, яка неправильно класифікувала багато дерев із тестового набору. Вона була **надто складною**. Якщо замінити її **простішою моделлю (наприклад, прямою лінією)**, така модель може краще узагальнювати нові дані.

Проста модель показує:

* гірші результати на навчальному наборі,
* але **кращі результати на тестовому наборі**.

Це ілюструє важливий принцип машинного навчання.

---

## Бритва Оккама

Ще із часів Стародавньої Греції простота вважалася перевагою. У XIV столітті Вільям з Оккама сформулював принцип, відомий як **бритва Оккама**:

> Серед моделей із подібною якістю слід обирати простішу.

Цей принцип є фундаментальним у машинному навчанні.

Важливе спостереження:

* **складні моделі краще підганяють навчальні дані**,
* **прості моделі часто краще працюють на нових даних**.

---

## Вибір кількості ознак

На початку проєкту машинного навчання зазвичай рекомендується:

* починати з **невеликої кількості ознак (1–3)**,
* обирати ознаки з **високою прогнозною цінністю**.

Додавання занадто великої кількості ознак може збільшити складність моделі та спричинити перенавчання.

---

## Регуляризація

Моделі машинного навчання мають досягати двох суперечливих цілей:

* добре адаптуватися до даних;
* залишатися якомога простішими.

**Регуляризація** — це підхід, який **штрафує складні моделі**, змушуючи їх бути простішими під час навчання.

Ідея регуляризації:

> мінімізувати не лише втрати, а й складність моделі.

---

## Втрати й складність

Якщо оптимізувати лише втрати, модель часто перенавчається.

Краща мета оптимізації:

мінімізувати
**втрати + складність моделі**

Проблема полягає в тому, що:

* зі збільшенням складності втрати зазвичай зменшуються;
* зі зменшенням складності втрати зростають.

Тому потрібно знайти **компроміс між втратами й складністю**, щоб модель добре працювала як на навчальних, так і на нових даних.

---

## Що таке складність моделі?

Складність можна оцінювати різними способами, наприклад:

* кількістю параметрів моделі;
* кількістю ознак;
* формою функції;
* величинами вагів моделі.

Регуляризація допомагає контролювати складність і покращувати узагальнення.



## Надмірне навчання: регуляризація L2

**L2-регуляризація** — популярний спосіб зменшення складності моделі. Вона обчислюється як **сума квадратів ваг моделі**.

Наприклад, для моделі з шістьма вагами:

| Вага | Значення | Квадрат           |
| ---- | -------- | ----------------- |
| w1   | 0.2      | 0.04              |
| w2   | −0.5     | 0.25              |
| w3   | 5.0      | 25.0              |
| w4   | −1.2     | 1.44              |
| w5   | 0.3      | 0.09              |
| w6   | −0.1     | 0.01              |
|      |          | **Усього: 26.83** |

Спостереження:

* ваги, близькі до нуля, майже не впливають на L2;
* великі ваги сильно збільшують значення регуляризації;
* одна велика вага може визначати більшість складності моделі.

**L2-регуляризація наближає ваги до нуля, але не робить їх рівними нулю.**

---

## Вплив L2-регуляризації

Під час навчання модель мінімізує:

**втрати + регуляризація**

Використання L2-регуляризації:

* зменшує складність моделі;
* знижує ризик перенавчання;
* не видаляє ознаки з моделі.

---

## Коефіцієнт регуляризації (λ)

Коефіцієнт регуляризації (**лямбда, λ**) визначає силу регуляризації:

**Втрати + λ × складність**

### Високий λ

* сильніша регуляризація
* менший ризик перенавчання
* ваги ближчі до нуля
* гістограма ваг має нормальний розподіл

### Низький λ

* слабка регуляризація
* більший ризик перенавчання
* ваги можуть бути великими
* розподіл ваг більш плоский

Якщо:

```
λ = 0
```

регуляризація повністю вимикається.

Оптимальне значення λ зазвичай знаходять експериментально.

---

## Рання зупинка (Early Stopping)

**Рання зупинка** — альтернативний метод регуляризації.

Ідея:
зупинити навчання, коли помилка на наборі перевірки починає зростати.

Цей підхід:

* швидкий;
* зменшує перенавчання;
* рідко дає оптимальний результат.

---

## Баланс між швидкістю навчання і регуляризацією

Швидкість навчання та регуляризація впливають на ваги протилежним чином:

* велика швидкість навчання → ваги збільшуються;
* велика регуляризація → ваги зменшуються.

Можливі проблеми:

* занадто велика регуляризація → модель недонавчається;
* занадто мала регуляризація → перенавчання.

Тому потрібно підбирати:

* швидкість навчання,
* коефіцієнт регуляризації,

разом, щоб знайти баланс.



## Надмірне навчання: інтерпретація кривих втрат

В ідеальному випадку крива втрат виглядає так:

* спочатку втрати великі,
* потім швидко зменшуються,
* зрештою стабілізуються на низькому рівні.

Однак на практиці криві втрат часто виглядають інакше.

---

## Вправа 1. Коливальна крива втрат

Якщо втрати коливаються хаотично і не збігаються, можливі такі рішення:

* перевірити дані та видалити некоректні приклади;
* збільшити розмір навчального набору;
* знизити швидкість навчання.

Такі коливання зазвичай означають:

* занадто велику швидкість навчання;
* шум у даних;
* недостатню кількість даних.

---

## Вправа 2. Крива втрат із різким стрибком

Можливі причини різкого зростання втрат:

* у даних є значення **NaN**;
* у наборі даних багато **викидів**.

---

## Вправа 3. Втрати при перевірці зростають

Ситуація:

* втрати навчання зменшуються,
* втрати перевірки зростають.

Це класична ознака:

**перенавчання (overfitting)**

Модель починає запам’ятовувати навчальні дані замість узагальнення.

---

## Вправа 4. Крива втрат зупиняється

Якщо крива втрат:

* спочатку зменшується,
* потім починає поводитися нестабільно або хвилеподібно,

це може означати:

* швидкість навчання зависока;
* оптимізація не збігається;
* модель "перестрибує" мінімум функції втрат.

Можливі рішення:

* зменшити швидкість навчання;
* застосувати регуляризацію;
* перевірити якість даних.

---

## Коротка пам’ятка

Тип кривої втрат → проблема:

* хаотичні коливання → зависока швидкість навчання або шумні дані
* різкий стрибок → NaN або викиди
* зростання втрат перевірки → перенавчання
* хвилеподібна стабілізація → проблеми зі збіжністю

Мета — отримати **плавне зменшення втрат із подальшою стабілізацією**.


## Нелінійні задачі класифікації та поєднання ознак

### Нелінійна класифікація

Нелінійна задача — це задача, у якій неможливо відокремити класи прямою лінією.

Тобто модель вигляду:

    y = w1x1 + w2x2 + b

не зможе правильно розділити дані.

У такому випадку поверхня рішень не є прямою лінією.

---

### Приклад 1: квадранти

Якщо:
- точки у правому верхньому та лівому нижньому квадрантах — сині,
- точки у лівому верхньому та правому нижньому — помаранчеві,

жодна пряма не зможе повністю їх розділити.

Але якщо додати нову ознаку:

    x3 = x1 * x2

тоді модель:

    y = w1x1 + w2x2 + w3(x1x2) + b

зможе навчитися гіперболічній межі,
яка правильно відокремить класи.

---

### Приклад 2: кругова структура

Якщо:
- сині точки розташовані в центрі,
- помаранчеві утворюють кільце навколо,

це ще складніша нелінійна задача.

Тут потрібно створювати складніші поєднання ознак,
наприклад:

    x1² + x2²

---

### Проблема ручного підбору ознак

Для складних даних потрібно:
- експериментувати,
- підбирати комбінації ознак,
- перевіряти якість моделі.

Це довго та неефективно.

---

### Рішення: нейронні мережі

Нейронні мережі:
- автоматично знаходять нелінійні закономірності,
- самі створюють оптимальні поєднання ознак,
- мінімізують функцію втрат під час навчання.

Тобто замість ручного конструювання ознак
мережа робить це самостійно.

---

### Висновок

Лінійна модель → працює тільки для лінійно роздільних даних.

Поєднання ознак → дозволяє моделі вивчати нелінійні межі.

Нейронні мережі → автоматизують пошук таких поєднань.



## Нейронні мережі: вузли й приховані шари

### Лінійна модель як нейронна мережа

Лінійну модель можна подати як найпростішу нейронну мережу:

    y = w1x1 + w2x2 + w3x3 + b

Де:
- x1, x2, x3 — вхідні вузли (input nodes)
- y — вихідний вузол (output node)
- w — ваги (weights)
- b — зміщення (bias)

Вузол обчислює:

    output = Linear(w·x + b)

Функція Linear() просто повертає значення без змін.

---

### Як параметри впливають на вихід

У лінійній моделі:

- зміна входів → змінює вихід
- зміна ваг → змінює вплив входів
- зміна зміщення → зсуває результат

Але модель залишається **лінійною незалежно від значень параметрів**.

---

## Приховані шари

Якщо додати шар між входом і виходом, отримуємо:

- вхідний шар (input layer)
- прихований шар (hidden layer)
- вихідний шар (output layer)

Вузли у прихованих шарах називаються **нейронами**.

---

### Обчислення в прихованому шарі

Кожен нейрон обчислює:

    h = w1x1 + w2x2 + w3x3 + b

тобто так само, як лінійна модель.

Вихідний шар використовує значення прихованого шару як вхід:

    y = v1h1 + v2h2 + v3h3 + v4h4 + b

---

### Навіщо потрібні приховані шари

Прихований шар дозволяє:
- рекомбінувати вхідні ознаки
- створювати нові представлення даних
- вивчати складніші закономірності

Фактично це автоматичне створення нових ознак.

---

### Важлива ідея

Без функції активації навіть багатошарова мережа
залишається лінійною моделлю.

Кілька лінійних перетворень = одне лінійне перетворення.

Саме тому потрібні **нелінійні функції активації**
(їх розглянемо далі).

---

## Висновок

Нейронна мережа складається з:
- вузлів (neurons)
- ваг
- зміщень
- шарів

Приховані шари дозволяють:
- комбінувати ознаки
- будувати складніші моделі
- готувати дані для нелінійного навчання.



## Алгоритм зворотного поширення помилки (Backpropagation)

**Зворотне поширення помилки (backpropagation)** — це основний алгоритм навчання нейронних мереж, який дозволяє застосовувати **градієнтний спуск** у багатошарових мережах.

Більшість бібліотек машинного навчання (наприклад, **Keras**, **TensorFlow**, **PyTorch**) виконують ці обчислення автоматично.

Ідея алгоритму:

1. Мережа обчислює прогноз (forward pass).
2. Обчислюється функція втрат.
3. Градієнти втрат поширюються назад через мережу.
4. Ваги оновлюються для зменшення втрат.

---

## Типові проблеми під час навчання нейронних мереж

### Зникання градієнтів (Vanishing gradients)

У глибоких мережах градієнти в нижніх шарах можуть ставати дуже малими.

Наслідки:

* нижні шари навчаються дуже повільно або не навчаються взагалі

Причина:

* множення багатьох малих значень під час backpropagation

Рішення:

* використання **ReLU**
* правильна ініціалізація ваг
* пакетна нормалізація

---

### Вибух градієнтів (Exploding gradients)

Якщо ваги дуже великі, градієнти можуть ставати надто великими.

Наслідки:

* навчання стає нестабільним
* модель не збігається

Рішення:

* **batch normalization**
* зменшення **learning rate**
* gradient clipping

---

### "Мертві" нейрони ReLU (Dead ReLU)

Якщо зважена сума входів стає меншою за 0:

```
ReLU(x) = max(0, x)
```

нейрон починає постійно повертати 0.

Наслідки:

* нейрон перестає впливати на модель
* градієнти не проходять через нього

Рішення:

* зменшити **learning rate**
* використовувати варіанти ReLU:

  * LeakyReLU
  * Parametric ReLU

---

## Регуляризація методом виключення (Dropout)

**Dropout** — це метод регуляризації, який випадково вимикає частину нейронів під час навчання.

Це:

* зменшує перенавчання
* робить модель стійкішою
* змушує мережу не покладатися на окремі нейрони

Значення dropout:

* `0.0` → без регуляризації
* `1.0` → вимкнено всі нейрони (модель не навчається)
* типові значення: **0.1–0.5**

---

## Висновок

Backpropagation дозволяє:

* обчислювати градієнти
* оновлювати ваги
* навчати багатошарові мережі

Типові проблеми навчання:

* зникання градієнтів
* вибух градієнтів
* мертві ReLU

Основні методи стабілізації:

* ReLU та його варіанти
* batch normalization
* dropout
* зменшення швидкості навчання




 
